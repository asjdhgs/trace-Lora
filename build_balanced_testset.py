import os
import json
import re
import math
import random

# ================= é…ç½®åŒºåŸŸ =================
BASE_DIR = "/home/fengxiaoyu/lx/LLAMA_NEW/data_transform/data/raw/total"
INPUT_DIRS = {
    "æ­£å¸¸": [os.path.join(BASE_DIR, "normal")],
    "å¼‚å¸¸": [os.path.join(BASE_DIR, "abnormal")],
}
SAMPLES_PER_CLASS = 500
RANDOM_SEED = 42
OUTPUT_FILE = "/home/fengxiaoyu/lx/LLAMA_NEW/data_transform/data/cooked/prediction/predict_balanced_pure.jsonl"

# âš ï¸ æ ¸å¿ƒï¼šæŠŠé€»è¾‘å†™åœ¨ Prompt é‡Œï¼Œè€Œä¸æ˜¯ Python ä»£ç é‡Œ
# æˆ‘ä»¬å‘Šè¯‰æ¨¡å‹æˆ‘ä»¬åœ¨ EDA ä¸­å‘ç°çš„è§„å¾‹ï¼Œè®©æ¨¡å‹è‡ªå·±å»æ¯”å¯¹
SYSTEM_PROMPT = (
    "ä½ æ˜¯ä¸€ä¸ªä¸“å®¶çº§è°ƒç”¨é“¾åˆ†æå¸ˆã€‚è¯·æ ¹æ®ç»™å®šçš„ Trace ç»Ÿè®¡æ•°æ®ï¼Œé€»è¾‘æ¨ç†å¹¶åˆ¤æ–­å…¶æ˜¯â€œæ­£å¸¸â€è¿˜æ˜¯â€œå¼‚å¸¸â€ã€‚\n\n"
    "ã€åˆ¤æ–­æ ‡å‡†ã€‘\n"
    "1. **å®Œæ•´æ€§æ£€æŸ¥**ï¼šæ­£å¸¸çš„ Trace å¿…é¡»åŒ…å«å®Œæ•´çš„è°ƒç”¨é“¾è·¯ï¼ˆnum_edges >= 9ï¼‰ã€‚å¦‚æœ num_edges < 9ï¼Œå±äºé“¾è·¯ä¸­æ–­ï¼ˆå¼‚å¸¸ï¼‰ã€‚\n"
    "2. **æ—¶å»¶æ£€æŸ¥**ï¼šæ­£å¸¸çš„ä¸šåŠ¡å¤„ç†è€—æ—¶é€šå¸¸åœ¨ **500ms åˆ° 2000ms** ä¹‹é—´ã€‚\n"
    "   - å¦‚æœ total_latency_ms < 500msï¼šé€šå¸¸æ„å‘³ç€è¯·æ±‚æœªå®Œæˆå³æŠ¥é”™è¿”å›ï¼ˆå¼‚å¸¸ï¼‰ã€‚\n"
    "   - å¦‚æœ total_latency_ms > 2000msï¼šé€šå¸¸æ„å‘³ç€ç³»ç»Ÿä¸¥é‡è¶…æ—¶ï¼ˆå¼‚å¸¸ï¼‰ã€‚\n\n"
    "ã€è¾“å‡ºè¦æ±‚ã€‘\n"
    "è¯·ä¸€æ­¥æ­¥æ€è€ƒï¼Œå°†æ•°æ®çš„æ•°å€¼ä¸ä¸Šè¿°æ ‡å‡†è¿›è¡Œæ¯”å¯¹ï¼Œæœ€åè¾“å‡ºç»“è®ºã€‚\n"
    "ç»“è®ºè¡Œå¿…é¡»ä¸¥æ ¼ä¸ºï¼šâ€œ====ç»“è®º====\næ­£å¸¸â€ æˆ– â€œ====ç»“è®º====\nå¼‚å¸¸â€ã€‚"
)
# ===========================================

START_FINISH_RE = re.compile(r"starts\s+at\s*(\d+)\s*ms.*?finishes\s+at\s*(\d+)\s*ms", re.IGNORECASE)

def parse_trace_and_stats(txt: str):
    """åªè´Ÿè´£è®¡ç®—åŸºç¡€ç‰¹å¾ï¼Œä¸åŒ…å«ä»»ä½•åˆ¤æ–­é€»è¾‘"""
    durations = []
    earliest, latest = None, None
    ann_lines = []
    lines = [l for l in txt.splitlines() if l.strip()]
    
    for raw in lines:
        line = raw
        if line.startswith('[') and 'starts at' in line and 'finishes at' in line:
            m = START_FINISH_RE.search(line)
            if m:
                s = int(m.group(1)); f = int(m.group(2))
                dur = max(0, f-s)
                durations.append(dur)
                if line.rstrip().endswith('].'):
                    line = line[:-2] + f", duration={dur} ms]."
                elif line.rstrip().endswith(']'):
                    line = line[:-1] + f", duration={dur} ms]"
                else:
                    line = line + f" (duration={dur} ms)"
                earliest = s if earliest is None else min(earliest, s)
                latest   = f if latest   is None else max(latest, f)
        ann_lines.append(line)

    num_edges = len(durations)
    total = max(0, latest - earliest) if (earliest is not None and latest is not None and latest >= earliest) else sum(durations)
    mx   = max(durations) if durations else 0
    avg  = int(sum(durations)/len(durations)) if durations else 0
    vs   = sorted(durations)
    idx  = max(0, min(len(vs)-1, math.ceil(0.95 * len(vs)) - 1)) if vs else 0
    p95  = int(vs[idx]) if vs else 0
    max_ratio = (mx/total) if total>0 else 0.0
    b_idx     = durations.index(mx) if durations else -1

    header = (
        f"# ç»Ÿè®¡ç‰¹å¾\n"
        f"num_edges={num_edges}\n"
        f"total_latency_ms={total}\n"
        f"max_edge_latency_ms={mx}\n"
        f"mean_edge_latency_ms={avg}\n"
        f"p95_edge_latency_ms={p95}\n"
        f"max_edge_ratio={max_ratio:.4f}\n"
        f"bottleneck_index={b_idx}\n"
    )
    
    return header + "\n" + "\n".join(ann_lines)

def main():
    random.seed(RANDOM_SEED)
    all_samples = []
    print(f"ğŸš€ å¼€å§‹æ„å»ºçº¯æ¨¡å‹æ¨ç†æ•°æ®é›†...")

    for label_name, dir_list in INPUT_DIRS.items():
        file_paths = []
        for d in dir_list:
            if not os.path.exists(d): continue
            for fn in os.listdir(d):
                if fn.endswith(".txt"):
                    file_paths.append(os.path.join(d, fn))
        
        if SAMPLES_PER_CLASS and len(file_paths) > SAMPLES_PER_CLASS:
            selected_files = random.sample(file_paths, SAMPLES_PER_CLASS)
        else:
            selected_files = file_paths

        for fp in selected_files:
            try:
                with open(fp, "r", encoding="utf-8") as f:
                    raw = f.read().strip()
                
                cooked_content = parse_trace_and_stats(raw)
                
                # æ„é€  User Input
                # ä¾ç„¶åŠ ä¸Š === Data End === é˜²æ­¢ç»­å†™ï¼Œä½†å†…å®¹é‡Œæ²¡æœ‰ä»»ä½•â€œæç¤ºâ€
                input_text = (
                    "=== Trace Data Start ===\n"
                    f"{cooked_content}\n"
                    "=== Trace Data End ===\n\n"
                    "è¯·æ ¹æ® System Prompt ä¸­çš„æ ‡å‡†ï¼Œåˆ†æä¸Šè¿°æ•°æ®çš„ num_edges å’Œ total_latency_msï¼Œå¹¶ç»™å‡ºç»“è®ºã€‚"
                )

                sample = {
                    "instruction": SYSTEM_PROMPT, # è§„åˆ™åœ¨è¿™é‡Œ
                    "input": input_text,          # æ•°æ®åœ¨è¿™é‡Œ
                    "output": "",
                    "label": label_name,
                    "id": os.path.basename(fp)
                }
                all_samples.append(sample)
            except Exception as e:
                print(f"Error {fp}: {e}")

    random.shuffle(all_samples)
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        for s in all_samples:
            f.write(json.dumps(s, ensure_ascii=False) + "\n")

    print(f"\nâœ… ç”Ÿæˆå®Œæ¯•: {OUTPUT_FILE}")
    print(f"ğŸ‘€ Prompt é¢„è§ˆ (User):\n{all_samples[0]['input'][-200:]}")

if __name__ == "__main__":
    main()